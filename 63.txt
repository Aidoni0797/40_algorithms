Понимание алгоритмических стратегий

Хороший алгоритм максимально оптимизирует использование доступных ресурсов, по возможности разбивая задачу на
более мелкие подзадачи. Существют различные алгоритмические стратегии для разработки алгоритмов.

В этом разделе мы рассмотрим:
- стратегию "разделяй и властвуй";
- стратегию динамического программирования;
- стратегию жадного алгоритма.

Стратегия "разделяй и властвуй"

Одна из стратегий состоит в том, чтобы разделить большую задач на более мелкие, которые можно решать
независимо друг от друга. Промежуточные решения, полученные при работе с этими подзадачами, затем
объединябтся в итоговое решение. Это и называется стратегией "разделяй и властвуй".

Математически, если мы решаем задаяу (Р) с n входными данными, в рамках которой необходимо обработать набор данных
d, мы разделяем ее на k подзадач, от Р1 до Рк. Каждая из подзадач будет обрабатывать свой раздел набор
данных d. Как правило, у нас будут подзадачи от Р1 до Рк, обрабатывающие данные от d1 до dk.

Обратимся к практическом примеру.

Практический пример - "разделяй и властвуй" применительно к Apache Spark

Apache Spark - это платформа с открытым исходным кодом, которую используют для решения сложных распределенных 
задач. В ней реализована стратегия "разделяй и властвуй". Задача делится на подзадачи, которые обрабатываются
независимо. Мы проедемонстрируем это на простом примере подсчета слов из списка.
Давайте преполоджим, что у нас имеется следющий список слов:

wordlist = [python, java, ottawa, news, java, ottawa]

Мы хотим подсчитать, сколько раз встречается каждое слово в этом списке, и для эффективного решения задачи применим 
стратегию "разделяй и властвуй".

Реализация принципа "разделяй и властвуй" показана на рисунке.

На рисунке показаны следующие этапы, на которые делится задача:

1. Разбиение (Splitting). Входные данные на части (сплиты), которые могут обрабатываться независимо. Это 
называется разбиением. На рисунке мы видим три сплита.

2. Маппинг (Mapping). Это любая операция, которую можно независимо применить к каждому сплиту. Как видно на диаграмме,
во время маппинга каждое слово в сплите отображается в виде пары "ключ - значение". В нашем примере имеются
три маппера, которые выполняются параллельно, в соответствии с тремя сплитами.

3. Перетасовка (Shuffling). Это процесс объединения одинаковых ключей. Как только аналогичные ключи объединены, 
к их значениям можно применять функции агрегирования. Обратите внимание, что перетасовка - это ресурсоемкая
операция, поскольку необходимо объединить аналогичные ключи, которые изначально могут быть разбросаны по сети.

4. Сокращение (Reducing). Выполнение функции агрегирования значений одинаковых ключей называется сокращением.
На рисунке нам нужно подсчитать количество одинаковых слов.

Давайте посмотрим, как мы можем реализовать решение в коде. Чтобы продемонстрировать стратегию "разделяй и властвуй",
нам понадобится платформа распределенных вычислений. Для этого запустим Python на Apache Spark.

1. Чтобы использовать Apache Spark, создадим контекст выполнения Apache Spark:

import findspark
findspark.init()
from pyspark.sql import SparkSssion
spark = SparkSession.builder.master("local[*]").getOrCreate()
sc = spark.sparkContext

2. Теперь создадим демонстрационный список, содержащий несколько слов. Мы преобразуем этот список во встроенную
распределенную структуру данных Spark, называемую устойчивым распределенным набором данных (RDD,
Resilient Distributed Dataset):

wordlist = ['python', 'java', 'ottawa', 'ottawa', 'java', 'news']
wordsRDD = sc.parallelize(wordlist,4)
#Напечатать тип wordsRDD
print(wordsRDD.collect())

3. Далее используем функцию map(), чтобы преобразовать слова в пары "ключ-значение".

wordPairs = wordsRDD.map(lambda w:(w,1))
print(wordPairs.collect())
[('python',1),('java',1),('ottawa',1),('ottawa',1),('java',1),('news',1)]

4. Наконец, используем функцию reduce() для агрегирования и получения конечного результата.

wordCountsCollected = wordPairs.reduceByKey(lambda x,y: x+y)
print(wordCountsCollected.collect())
[('python',1),('java',2),('ottawa',2),('news',1)]

Данный код демонстрирует, как мы можем использовать стратегию "разделяй и властвуй" длдя подсчета количества
одинаковых слов.

Современные инфраструктуры облачных вычислений, такие как Microsoft Azure, Amazon Web Services and Google Cloud, 
обеспечивают масштабируемость за счет прямой и косвенной реализации стратегии "разделяй и властвуй".

